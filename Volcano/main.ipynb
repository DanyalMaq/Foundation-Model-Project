{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4517483bebb74ff2888163e810dff45b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f5496b836024d8db93e73555e50328b",
              "IPY_MODEL_f6f2b6f20245462282490fb4865a315a",
              "IPY_MODEL_12f7416b16d34f798f96d64acf85194f"
            ],
            "layout": "IPY_MODEL_eb772e8a86fe475d9071c1abfa3ac840"
          }
        },
        "4f5496b836024d8db93e73555e50328b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f6a8e64fb214b8a9edc39dd476578e4",
            "placeholder": "​",
            "style": "IPY_MODEL_66d56e310fa3477fb55b68f2e904d3b7",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "f6f2b6f20245462282490fb4865a315a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c0de9da8fdd46ebb093fb9915e55cc8",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22d6e112e1344696a2ccb6f8c9a0a57d",
            "value": 2
          }
        },
        "12f7416b16d34f798f96d64acf85194f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3973c5282bc6454dac035136a8d24dd0",
            "placeholder": "​",
            "style": "IPY_MODEL_176b4d297cbd4daa89f742bd64add0db",
            "value": " 2/2 [00:01&lt;00:00,  1.67it/s]"
          }
        },
        "eb772e8a86fe475d9071c1abfa3ac840": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f6a8e64fb214b8a9edc39dd476578e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66d56e310fa3477fb55b68f2e904d3b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c0de9da8fdd46ebb093fb9915e55cc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22d6e112e1344696a2ccb6f8c9a0a57d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3973c5282bc6454dac035136a8d24dd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "176b4d297cbd4daa89f742bd64add0db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ro2wAChM-v0"
      },
      "outputs": [],
      "source": [
        "# I would reo\n",
        "\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import torch\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration\n",
        "from transformers import AutoProcessor, AutoModelForImageTextToText"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "!pip install --upgrade -q accelerate bitsandbytes\n",
        "!pip install git+https://github.com/huggingface/transformers.git\n",
        "!pip install qwen-vl-utils\n",
        "!pip install flash-attn --no-build-isolation # If this doesn't install you can ignore"
      ],
      "metadata": {
        "id": "eeE_gvwR1GHu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb0d3d99-3cae-448e-fcf5-d490d574cc04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-msy263xw\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-msy263xw\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 98e8062df3cf82b367e8a243963e4afb0d9d3407\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (0.26.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (2.32.3)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers==4.48.0.dev0)\n",
            "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.0.dev0) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.0.dev0) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.0.dev0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.48.0.dev0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.48.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.48.0.dev0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.48.0.dev0) (2024.8.30)\n",
            "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.48.0.dev0-py3-none-any.whl size=10133629 sha256=d1090bd0770ef4621d158f83be928e9584c2659e2f8f052b6e500407a948a495\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-y4rk8l4g/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\n",
            "Successfully built transformers\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.20.3\n",
            "    Uninstalling tokenizers-0.20.3:\n",
            "      Successfully uninstalled tokenizers-0.20.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.46.3\n",
            "    Uninstalling transformers-4.46.3:\n",
            "      Successfully uninstalled transformers-4.46.3\n",
            "Successfully installed tokenizers-0.21.0 transformers-4.48.0.dev0\n",
            "Collecting qwen-vl-utils\n",
            "  Downloading qwen_vl_utils-0.0.8-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting av (from qwen-vl-utils)\n",
            "  Downloading av-14.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from qwen-vl-utils) (24.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from qwen-vl-utils) (11.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from qwen-vl-utils) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->qwen-vl-utils) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->qwen-vl-utils) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->qwen-vl-utils) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->qwen-vl-utils) (2024.8.30)\n",
            "Downloading qwen_vl_utils-0.0.8-py3-none-any.whl (5.9 kB)\n",
            "Downloading av-14.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.0/33.0 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: av, qwen-vl-utils\n",
            "Successfully installed av-14.0.0 qwen-vl-utils-0.0.8\n",
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.7.0.post2.tar.gz (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn) (2.5.1+cu121)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash-attn) (0.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->flash-attn) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn) (3.0.2)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.7.0.post2-cp310-cp310-linux_x86_64.whl size=183291101 sha256=16a849d51b95cf8e47a6e6cd36826e9ffbbc068a8546e7e3501a598bd70905a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/e3/ed/5e845387d52f2debd1bafb847bf3d774d3f0a3c8e31b1dc948\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: flash-attn\n",
            "Successfully installed flash-attn-2.7.0.post2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BitsAndBytesConfig, LlavaOnevisionForConditionalGeneration, LlavaOnevisionProcessor\n",
        "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
        "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
        "from qwen_vl_utils import process_vision_info\n",
        "import torch\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "# model = LlavaOnevisionForConditionalGeneration.from_pretrained(\"llava-hf/llava-onevision-qwen2-0.5b-ov-hf\", torch_dtype=\"float16\", device_map='auto')\n",
        "# processor = LlavaOnevisionProcessor.from_pretrained(\"llava-hf/llava-onevision-qwen2-0.5b-ov-hf\")\n",
        "# processor.tokenizer.padding_side = \"left\"\n",
        "\n",
        "\n",
        "# processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\")\n",
        "# model = AutoModelForImageTextToText.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\")\n",
        "# model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
        "#     \"Qwen/Qwen2-VL-2B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\"\n",
        "# )\n",
        "\n",
        "# We recommend enabling flash_attention_2 for better acceleration and memory saving, especially in multi-image and video scenarios.\n",
        "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
        "    \"Qwen/Qwen2-VL-2B-Instruct\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    # attn_implementation=\"flash_attention_2\",\n",
        "    device_map=\"cpu\",\n",
        ")\n",
        "\n",
        "# default processer\n",
        "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4517483bebb74ff2888163e810dff45b",
            "4f5496b836024d8db93e73555e50328b",
            "f6f2b6f20245462282490fb4865a315a",
            "12f7416b16d34f798f96d64acf85194f",
            "eb772e8a86fe475d9071c1abfa3ac840",
            "2f6a8e64fb214b8a9edc39dd476578e4",
            "66d56e310fa3477fb55b68f2e904d3b7",
            "6c0de9da8fdd46ebb093fb9915e55cc8",
            "22d6e112e1344696a2ccb6f8c9a0a57d",
            "3973c5282bc6454dac035136a8d24dd0",
            "176b4d297cbd4daa89f742bd64add0db"
          ]
        },
        "id": "xRI1lzKu1DMS",
        "outputId": "a4160c47-afbc-4c70-9d90-bf9f6ae0a590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4517483bebb74ff2888163e810dff45b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(image_file):\n",
        "    image = None\n",
        "    try:\n",
        "      if image_file.startswith('http') or image_file.startswith('https'):\n",
        "          response = requests.get(image_file)\n",
        "          image = Image.open(BytesIO(response.content)).convert('RGB')\n",
        "      else:\n",
        "          image = Image.open(image_file).convert('RGB')\n",
        "    except:\n",
        "      print(\"There was an error reading the image file\", image_file)\n",
        "    return image\n",
        "\n",
        "def generate_llama_onevision(model, processor, image, text):\n",
        "  conversation = [\n",
        "      {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": [\n",
        "              {\"type\": \"text\", \"text\": text},\n",
        "              {\"type\": \"image\"}\n",
        "          ]\n",
        "      }\n",
        "  ]\n",
        "\n",
        "  prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
        "  inputs = processor(images=[image], text=[prompt], padding=True, return_tensors=\"pt\").to(model.device, torch.float16)\n",
        "  generate_kwargs = {\"max_new_tokens\": 50, \"do_sample\": True, \"top_p\": 0.9}\n",
        "  output = model.generate(**inputs, **generate_kwargs)\n",
        "  generated_text = processor.batch_decode(output, skip_special_tokens=True)\n",
        "  response = generated_text[0].split(\"assistant\\n\")[1]\n",
        "  return response\n",
        "\n",
        "def generate_qwenvl(model, processor, image_path, text):\n",
        "  conversation = [\n",
        "      {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": [\n",
        "              {\n",
        "                  \"type\": \"image\",\n",
        "                  \"image\": f\"{image_path}\",\n",
        "              },\n",
        "              {\"type\": \"text\", \"text\": text},\n",
        "          ],\n",
        "      }\n",
        "  ]\n",
        "\n",
        "  text = processor.apply_chat_template(\n",
        "      conversation, tokenize=False, add_generation_prompt=True\n",
        "  )\n",
        "  image_inputs, video_inputs = process_vision_info(conversation)\n",
        "  inputs = processor(\n",
        "      text=[text],\n",
        "      images=image_inputs,\n",
        "      videos=video_inputs,\n",
        "      padding=True,\n",
        "      return_tensors=\"pt\",\n",
        "  )\n",
        "  inputs = inputs.to(model.device)\n",
        "\n",
        "  # Inference: Generation of the output\n",
        "  generated_ids = model.generate(**inputs, max_new_tokens=128)\n",
        "  generated_ids_trimmed = [\n",
        "      out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
        "  ]\n",
        "  output_text = processor.batch_decode(\n",
        "      generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
        "  )\n",
        "  return output_text"
      ],
      "metadata": {
        "id": "s66rpC_rz1gS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_qwenvl(model, processor, \"https://c4.staticflickr.com/8/7211/7206072054_c53d53b97d_o.jpg\", \"What is happening in this image?\")"
      ],
      "metadata": {
        "id": "-1JPJhjyaN89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(json_file, output):\n",
        "\n",
        "    # Load input JSON data\n",
        "    with open(json_file, 'r') as f:\n",
        "        json_data = json.load(f)\n",
        "\n",
        "    logs = []\n",
        "    iter_cnt = {1: 0, 2: 0, 3: 0}\n",
        "\n",
        "    for idx, line in tqdm(enumerate(json_data)):\n",
        "        image_src = line['image_src']\n",
        "        image = load_image(image_src)\n",
        "        if image == None:\n",
        "          continue\n",
        "        question = line['question']\n",
        "        qs = question\n",
        "\n",
        "        # Initial question generation\n",
        "        initial_answer = generate(model, processor, image, question)\n",
        "        outputs = initial_answer\n",
        "        revision = None\n",
        "\n",
        "        print('Initial output:', outputs)\n",
        "\n",
        "        # Feedback and refinement loop\n",
        "        for i in range(3):\n",
        "            fqs = (\n",
        "                \"Generate the feedback given initial answer referring to question and image.\\n\"\n",
        "                f\"Question: {question}\\nInitial answer: {outputs}\"\n",
        "            )\n",
        "            feedback1 = generate(model, processor, image, fqs)\n",
        "            print('Feedback:', feedback1)\n",
        "\n",
        "            rqs = (\n",
        "                \"Adjust the initial response considering the feedback and image.\\n\"\n",
        "                f\"Question: {question}\\nInitial answer: {outputs}\\nFeedback: {feedback1}\"\n",
        "            )\n",
        "            revision = generate(model, processor, image, rqs)\n",
        "            print(\"Revision:\", revision)\n",
        "\n",
        "            comparison_prompt = (\n",
        "                f\"{question}\\nA. {outputs}\\nB. {revision}\\n\"\n",
        "                \"Answer with the option's letter from the given choices directly.\"\n",
        "            )\n",
        "            comparison_result = generate(model, processor, image, comparison_prompt)\n",
        "\n",
        "            print('Answer comparison:', comparison_result)\n",
        "\n",
        "            if 'b' in comparison_result.lower():\n",
        "                outputs = revision\n",
        "            elif 'a' in comparison_result.lower():\n",
        "                break\n",
        "\n",
        "        iter_cnt[i + 1] += 1\n",
        "\n",
        "        # Logging results\n",
        "        logs.append({\n",
        "            'question': question,\n",
        "            'gold answer': line['gt_answer'],\n",
        "            'initial answer': initial_answer,\n",
        "            'feedback': feedback1,\n",
        "            'revision': revision,\n",
        "        })\n",
        "\n",
        "        line['model_answer'] = outputs\n",
        "        print('---------------------------------')\n",
        "        print('question: ', question)\n",
        "        print('answer: ', line['gt_answer'])\n",
        "        print('initial pred: ', initial_answer)\n",
        "        print('pred: ', outputs)\n",
        "        print('---------------------------------')\n",
        "\n",
        "    with open(output, 'w') as f:\n",
        "        json.dump(json_data, f, indent=\"\\t\")\n",
        "\n",
        "    return logs"
      ],
      "metadata": {
        "id": "xxSyVwmzz0Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model(\"response_template.json\", \"output.json\")"
      ],
      "metadata": {
        "id": "iouiVZWmhim7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "quTB6qCiwjD8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}